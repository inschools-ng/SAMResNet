{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUTrpuFGVpdA",
        "outputId": "d2c488d3-a102-447f-fc28-05872d331294"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->thop)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->thop)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->thop)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->thop)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->thop)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->thop)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import SGD\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import random\n",
        "\n",
        "def set_random_seeds(seed=42):\n",
        "    \"\"\"Set random seeds for reproducibility across all libraries.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    print(f\"Random seeds set to {seed} for reproducibility\")\n",
        "\n",
        "\n",
        "set_random_seeds(84)\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = '/content/drive/MyDrive/3_DL_Project1_CIFAR10'\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "print(f\"Google Drive mounted. Files will be saved to {DRIVE_PATH}\")\n",
        "\n",
        "# MODEL ARCHITECTURE COMPONENTS\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels//reduction, 1, bias=True),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Conv2d(channels//reduction, channels, 1, bias=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x): return x * self.se(x)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, stride=1, se=True):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.se = SEBlock(out_channels) if se else None\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.silu(self.bn1(self.conv1(x)))\n",
        "        if self.se: out = self.se(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return F.silu(out)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_blocks, num_channels=64, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.in_channels = num_channels\n",
        "        self.conv1 = nn.Conv2d(3, num_channels, 3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.layer1 = self._make_layer(num_channels, num_blocks[0], 1)\n",
        "        self.layer2 = self._make_layer(num_channels*2, num_blocks[1], 2)\n",
        "        self.layer3 = self._make_layer(num_channels*4, num_blocks[2], 2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.linear = nn.Linear(num_channels*4 * BasicBlock.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(BasicBlock(self.in_channels, out_channels, stride, se=True))\n",
        "            self.in_channels = out_channels * BasicBlock.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.silu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avgpool(out)\n",
        "        return self.linear(out.view(out.size(0), -1))\n",
        "\n",
        "# EMA MODEL IMPLEMENTATION\n",
        "class ModelEMA:\n",
        "    \"\"\" Model Exponential Moving Average \"\"\"\n",
        "    def __init__(self, model, decay=0.9999, device=None):\n",
        "        self.ema = {k: v.clone().detach() for k, v in model.state_dict().items()}\n",
        "        self.decay = decay\n",
        "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.ema = {k: v.to(device) for k, v in self.ema.items()}\n",
        "        self.model = model\n",
        "        self.training_mode = False\n",
        "\n",
        "    def update(self, model):\n",
        "        with torch.no_grad():\n",
        "            for k, v in model.state_dict().items():\n",
        "                if v.dtype.is_floating_point:\n",
        "                    self.ema[k] = self.ema[k] * self.decay + v.detach() * (1 - self.decay)\n",
        "\n",
        "    def apply(self):\n",
        "        self.training_mode = self.model.training\n",
        "        self.ema_state_dict = self.model.state_dict()\n",
        "        self.model.load_state_dict({k: v.clone() for k, v in self.ema.items()})\n",
        "        self.model.eval()\n",
        "\n",
        "    def restore(self):\n",
        "        if self.training_mode:\n",
        "            self.model.load_state_dict(self.ema_state_dict)\n",
        "            self.model.train()\n",
        "\n",
        "# MIXUP/CUTMIX IMPLEMENTATION\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def cutmix_data(x, y, alpha=1.0):\n",
        "    '''Returns cutmix inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
        "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
        "    # lambda exactly matches pixel ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
        "\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, y_a, y_b, lam\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "# CUTOUT AUGMENTATION\n",
        "class Cutout:\n",
        "    def __init__(self, n_holes=1, length=16):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        h, w = img.shape[1], img.shape[2]\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "        for _ in range(self.n_holes):\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "            y1 = np.clip(y - self.length//2, 0, h)\n",
        "            y2 = np.clip(y + self.length//2, 0, h)\n",
        "            x1 = np.clip(x - self.length//2, 0, w)\n",
        "            x2 = np.clip(x + self.length//2, 0, w)\n",
        "            mask[y1:y2, x1:x2] = 0.\n",
        "        return img * torch.from_numpy(mask)\n",
        "\n",
        "# DATA PIPELINE\n",
        "def get_cifar10_loaders(batch_size=128):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        Cutout(n_holes=1, length=16),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "    train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    return DataLoader(train_set, batch_size, shuffle=True, num_workers=4, pin_memory=True), \\\n",
        "           DataLoader(test_set, batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Custom dataset for competition test data\n",
        "class CustomCIFAR10TestDataset(Dataset):\n",
        "    def __init__(self, file_path, transform=None):\n",
        "        print(f\"Loading test data from {file_path}...\")\n",
        "        try:\n",
        "            with open(file_path, 'rb') as f:\n",
        "                self.data_dict = pickle.load(f, encoding='bytes')\n",
        "\n",
        "            # keys to help debug\n",
        "            print(f\"Keys in the test data file: {list(self.data_dict.keys())}\")\n",
        "\n",
        "            # byte keys to strings for easier handling if needed\n",
        "            if isinstance(list(self.data_dict.keys())[0], bytes):\n",
        "                self.data_dict = {k.decode('utf-8') if isinstance(k, bytes) else k: v\n",
        "                                  for k, v in self.data_dict.items()}\n",
        "                print(f\"Converted keys: {list(self.data_dict.keys())}\")\n",
        "\n",
        "            # different possible structures of the test file\n",
        "            if 'data' in self.data_dict:\n",
        "                self.data = self.data_dict['data']\n",
        "            elif b'data' in self.data_dict:\n",
        "                self.data = self.data_dict[b'data']\n",
        "            else:\n",
        "                # If no 'data' key, check if the file itself is the data array\n",
        "                if isinstance(self.data_dict, np.ndarray):\n",
        "                    self.data = self.data_dict\n",
        "                else:\n",
        "                    raise KeyError(f\"No 'data' key found in test file and not a numpy array\")\n",
        "\n",
        "            # Reshape data to images format if needed\n",
        "            if len(self.data.shape) == 2:  # [N, 3072] format\n",
        "                print(f\"Reshaping data from {self.data.shape} to [N,3,32,32]\")\n",
        "                self.data = self.data.reshape(-1, 3, 32, 32)\n",
        "                # Convert from [N,3,32,32] to [N,32,32,3] for transforms\n",
        "                self.data = self.data.transpose(0, 2, 3, 1)\n",
        "\n",
        "            print(f\"Test data shape: {self.data.shape}\")\n",
        "\n",
        "            # Generate IDs based on index since we don't have filenames\n",
        "            self.ids = [f\"{i:05d}\" for i in range(len(self.data))]\n",
        "\n",
        "            self.transform = transform\n",
        "\n",
        "            print(f\"Loaded {len(self.data)} test images with ID format: {self.ids[0]} (example)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading test data: {str(e)}\")\n",
        "            print(f\"Current working directory: {os.getcwd()}\")\n",
        "            print(f\"Files in directory:\")\n",
        "            print(os.listdir())\n",
        "            raise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.data[idx]\n",
        "        img_id = self.ids[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, img_id\n",
        "\n",
        "def get_competition_test_loader(file_path, batch_size=128):\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "    test_set = CustomCIFAR10TestDataset(file_path, transform=transform_test)\n",
        "    return DataLoader(test_set, batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "''' #%% TEST TIME AUGMENTATION\n",
        "def tta_predict(model, img, num_aug=10):\n",
        "    \"\"\"Test-time augmentation prediction function.\"\"\"\n",
        "    model.eval()\n",
        "    img = img.clone()  # '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "SA-uiaJrVva-",
        "outputId": "45894fce-cf36-426a-b492-816c75685e16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seeds set to 84 for reproducibility\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted. Files will be saved to /content/drive/MyDrive/3_DL_Project1_CIFAR10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' #%% TEST TIME AUGMENTATION\\ndef tta_predict(model, img, num_aug=10):\\n    \"\"\"Test-time augmentation prediction function.\"\"\"\\n    model.eval()\\n    img = img.clone()  # '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "# Copy from Drive to current directory\n",
        "drive_test_file = os.path.join('/content/drive/MyDrive/3_DL_Project1_CIFAR10', 'cifar_test_nolabel.pkl')\n",
        "if os.path.exists(drive_test_file):\n",
        "    copyfile(drive_test_file, 'cifar_test_nolabel.pkl')\n",
        "    print(\"Test file copied from Google Drive backup\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fNmcg9zPMpA",
        "outputId": "991e0af5-8ee1-48dc-c8f9-670419ccf4bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test file copied from Google Drive backup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tta_predict(model, img, num_aug=10):\n",
        "    \"\"\"Enhanced Test-time augmentation with more diverse but controlled transformations.\"\"\"\n",
        "    model.eval()\n",
        "    img = img.clone()\n",
        "    predictions = []\n",
        "\n",
        "    # Original prediction (with temperature scaling to reduce overconfidence)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img) / 1.2  # Soften predictions with temperature\n",
        "        predictions.append(outputs)\n",
        "\n",
        "    # Horizontal flip (essential for CIFAR-10)\n",
        "    with torch.no_grad():\n",
        "        flipped = torch.flip(img, dims=[3])\n",
        "        outputs = model(flipped) / 1.2\n",
        "        predictions.append(outputs)\n",
        "\n",
        "    # Small shifts (1 pixel in each direction)\n",
        "    with torch.no_grad():\n",
        "        shifted = F.pad(img[:, :, 1:, :], (0, 0, 0, 1), mode='replicate')\n",
        "        outputs = model(shifted) / 1.2\n",
        "        predictions.append(outputs)\n",
        "\n",
        "        shifted = F.pad(img[:, :, :, 1:], (1, 0, 0, 0), mode='replicate')\n",
        "        outputs = model(shifted) / 1.2\n",
        "        predictions.append(outputs)\n",
        "\n",
        "    # Small brightness adjustments\n",
        "    with torch.no_grad():\n",
        "        brightened = img * 1.05  # +5% brightness\n",
        "        brightened = torch.clamp(brightened, 0, 1)\n",
        "        outputs = model(brightened) / 1.2\n",
        "        predictions.append(outputs)\n",
        "\n",
        "        darkened = img * 0.95  # -5% brightness\n",
        "        outputs = model(darkened) / 1.2\n",
        "        predictions.append(outputs)\n",
        "\n",
        "    # weighted average with higher weight for original prediction\n",
        "    weights = torch.tensor([1.5] + [1.0] * (len(predictions) - 1)).to(img.device)\n",
        "    weights = weights / weights.sum()\n",
        "\n",
        "    weighted_preds = torch.stack([(w * p) for w, p in zip(weights, predictions)])\n",
        "    return weighted_preds.sum(0)\n",
        "\n",
        "    # Average predictions\n",
        "    return torch.stack(predictions).mean(0)\n",
        "\n",
        "# OPTIMIZATION AND TRAINING\n",
        "class Lookahead(torch.optim.Optimizer):\n",
        "    def __init__(self, base_optimizer, k=5, alpha=0.5):\n",
        "        self.optimizer = base_optimizer\n",
        "        self.k = k\n",
        "        self.alpha = alpha\n",
        "        self.param_groups = self.optimizer.param_groups\n",
        "        self.defaults = self.optimizer.defaults\n",
        "        self.state = defaultdict(dict)\n",
        "        for group in self.param_groups:\n",
        "            group[\"counter\"] = 0\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = self.optimizer.step(closure)\n",
        "        for group in self.param_groups:\n",
        "            group[\"counter\"] += 1\n",
        "            if group[\"counter\"] >= self.k:\n",
        "                for p in group[\"params\"]:\n",
        "                    param_state = self.state[p]\n",
        "                    if \"slow_param\" not in param_state:\n",
        "                        param_state[\"slow_param\"] = p.data.clone()\n",
        "                    param_state[\"slow_param\"].add_(p.data - param_state[\"slow_param\"], alpha=self.alpha)\n",
        "                    p.data.copy_(param_state[\"slow_param\"])\n",
        "                group[\"counter\"] = 0\n",
        "        return loss\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "def train_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    train_loader, test_loader = get_cifar10_loaders()\n",
        "\n",
        "    model = ResNet([4, 4, 3]).to(device)\n",
        "    base_optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "    optimizer = Lookahead(base_optimizer)\n",
        "\n",
        "    # EMA model with reduced decay rate\n",
        "    ema_model = ModelEMA(model, decay=0.999, device=device)  # Reduced from 0.9995\n",
        "\n",
        "    # Warmup period for better stability with MixUp\n",
        "    warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "        optimizer.optimizer, start_factor=0.01, total_iters=10*len(train_loader)  # Extended from 5 to 10 epochs\n",
        "    )\n",
        "\n",
        "    # OneCycleLR for better compatibility with MixUp\n",
        "    main_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer.optimizer, max_lr=0.1, total_steps=200*len(train_loader), pct_start=0.4  # Increased from 0.3 to 0.4\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    best_acc = 0.0\n",
        "    model_save_path = os.path.join(DRIVE_PATH, \"best_model.pth\")\n",
        "    ema_model_save_path = os.path.join(DRIVE_PATH, \"best_ema_model.pth\")\n",
        "\n",
        "    # Training configurations - We use only MixUp with reduced alpha\n",
        "    use_mixup = True\n",
        "    use_cutmix = False  # Disabled CutMix\n",
        "    mixup_alpha = 0.3   # Reduced from 0.8 to 0.3\n",
        "    cutmix_alpha = 0.0  # Not used\n",
        "    mixup_prob = 1.0    # we use MixUp\n",
        "\n",
        "    for epoch in range(200):\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "\n",
        "            # We start with a lower alpha and gradually increase it\n",
        "            if epoch < 50:\n",
        "                current_mixup_alpha = mixup_alpha * 0.5  # Half strength at the beginning\n",
        "            elif epoch < 100:\n",
        "                current_mixup_alpha = mixup_alpha * 0.75  # 75% strength in the middle\n",
        "            else:\n",
        "                current_mixup_alpha = mixup_alpha  # Full strength later\n",
        "\n",
        "            # we apply only MixUp (no CutMix)\n",
        "            if use_mixup:\n",
        "                inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, current_mixup_alpha)\n",
        "            else:\n",
        "                targets_a, targets_b, lam = targets, targets, 1.0\n",
        "\n",
        "            with torch.cuda.amp.autocast(dtype=torch.float16):\n",
        "                outputs = model(inputs)\n",
        "                if use_mixup:\n",
        "                    loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "                else:\n",
        "                    loss = criterion(outputs, targets)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # EMA model updated\n",
        "            ema_model.update(model)\n",
        "\n",
        "            # Extended warmup period\n",
        "            if epoch < 10:  # Extended from 5 to 10 epochs\n",
        "                warmup_scheduler.step()\n",
        "            main_scheduler.step()\n",
        "\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # For accuracy calculation with mixup or cutmix\n",
        "            if use_mixup or use_cutmix:\n",
        "                _, predicted = outputs.max(1)\n",
        "                correct += (lam * predicted.eq(targets_a).sum().float()\n",
        "                          + (1 - lam) * predicted.eq(targets_b).sum().float()).item()\n",
        "            else:\n",
        "                _, predicted = outputs.max(1)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            total += targets.size(0)\n",
        "\n",
        "        # Evaluate with EMA model\n",
        "        ema_model.apply()  # Apply EMA weights\n",
        "        test_acc = evaluate(model, test_loader, device)\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(model.state_dict(), ema_model_save_path)\n",
        "            print(f\"New best EMA model saved at epoch {epoch+1} with accuracy {best_acc:.2f}%\")\n",
        "        ema_model.restore()  # Restore original weights\n",
        "\n",
        "        # Also evaluate and save the regular model\n",
        "        regular_test_acc = evaluate(model, test_loader, device)\n",
        "        if regular_test_acc > best_acc - 0.5:  # We allow slightly worse performance for diversity\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print(f\"Regular model saved at epoch {epoch+1} with accuracy {regular_test_acc:.2f}%\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/200: Loss: {total_loss/total:.4f} | \"\n",
        "              f\"Train Acc: {100.*correct/total:.2f}% | Test Acc: {test_acc:.2f}% (EMA) / {regular_test_acc:.2f}% | \"\n",
        "              f\"LR: {optimizer.optimizer.param_groups[0]['lr']:.5f}\")\n",
        "\n",
        "    print(f\"\\nTraining Complete. Best Accuracy: {best_acc:.2f}%\")\n",
        "    print(f\"Best EMA model saved to {ema_model_save_path}\")\n",
        "    print(f\"Regular model saved to {model_save_path}\")\n",
        "\n",
        "# EVALUATION AND SUBMISSION\n",
        "def evaluate(model, loader, device, use_tta=False):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            if isinstance(targets, list) or isinstance(targets[0], str):  # Skip if targets are just IDs\n",
        "                continue\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            if use_tta:\n",
        "                outputs = tta_predict(model, inputs)\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "\n",
        "            correct += outputs.argmax(1).eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "    return 100. * correct / total if total > 0 else 0.0\n",
        "\n",
        "def create_submission(test_file_path=\"cifar_test_nolabel.pkl\", use_tta=True, use_ensemble=True, ensemble_weights=None):\n",
        "    # Define paths for model and submission\n",
        "    model_path = os.path.join(DRIVE_PATH, \"best_model.pth\")\n",
        "    ema_model_path = os.path.join(DRIVE_PATH, \"best_ema_model.pth\")\n",
        "    submission_path = os.path.join(DRIVE_PATH, \"submission.csv\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load models\n",
        "    model = ResNet([4, 4, 3]).to(device)\n",
        "    ema_model = None\n",
        "\n",
        "    if use_ensemble and os.path.exists(ema_model_path):\n",
        "        ema_model = ResNet([4, 4, 3]).to(device)\n",
        "        try:\n",
        "            ema_model.load_state_dict(torch.load(ema_model_path, map_location=device, weights_only=True))\n",
        "            print(f\"EMA model loaded successfully from {ema_model_path} with weights_only=True\")\n",
        "        except Exception as e1:\n",
        "            print(f\"Error loading EMA model with weights_only=True: {str(e1)}\")\n",
        "            try:\n",
        "                ema_model.load_state_dict(torch.load(ema_model_path, map_location=device))\n",
        "                print(f\"EMA model loaded successfully from {ema_model_path} with standard loading\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading EMA model with standard loading: {str(e2)}\")\n",
        "                ema_model = None\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
        "        print(f\"Model loaded successfully from {model_path} with weights_only=True\")\n",
        "    except Exception as e1:\n",
        "        print(f\"Error loading model with weights_only=True: {str(e1)}\")\n",
        "        try:\n",
        "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "            print(f\"Model loaded successfully from {model_path} with standard loading\")\n",
        "        except Exception as e2:\n",
        "            print(f\"Error loading model with standard loading: {str(e2)}\")\n",
        "            return\n",
        "\n",
        "    model.eval()\n",
        "    if ema_model:\n",
        "        ema_model.eval()\n",
        "\n",
        "    # default ensemble weights if not provided\n",
        "    if ensemble_weights is None:\n",
        "        if ema_model:\n",
        "            ensemble_weights = [0.4, 0.6]  # We give slightly more weight to EMA model\n",
        "        else:\n",
        "            ensemble_weights = [1.0]\n",
        "\n",
        "    # competition test loader\n",
        "    test_loader = get_competition_test_loader(test_file_path)\n",
        "\n",
        "    #  predictions\n",
        "    inference_type = \"TTA\" if use_tta else \"standard inference\"\n",
        "    ensemble_type = \"ensemble\" if use_ensemble and ema_model else \"single model\"\n",
        "    print(f\"Generating predictions with {inference_type} and {ensemble_type}...\")\n",
        "\n",
        "    if use_ensemble and ema_model:\n",
        "        print(f\"Using ensemble weights: Regular model: {ensemble_weights[0]}, EMA model: {ensemble_weights[1]}\")\n",
        "\n",
        "    predictions = []\n",
        "    ids = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, batch_ids in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            if use_tta:\n",
        "                # predictions with TTA\n",
        "                outputs = tta_predict(model, inputs)\n",
        "                if ema_model and use_ensemble:\n",
        "                    ema_outputs = tta_predict(ema_model, inputs)\n",
        "                    # Weighted ensemble\n",
        "                    outputs = outputs * ensemble_weights[0] + ema_outputs * ensemble_weights[1]\n",
        "            else:\n",
        "                # Standard inference\n",
        "                outputs = model(inputs)\n",
        "                if ema_model and use_ensemble:\n",
        "                    ema_outputs = ema_model(inputs)\n",
        "                    # Weighted ensemble\n",
        "                    outputs = outputs * ensemble_weights[0] + ema_outputs * ensemble_weights[1]\n",
        "\n",
        "            # softmax to get probabilities\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "            # argmax for final class prediction\n",
        "            pred_labels = probs.argmax(1).tolist()\n",
        "            predictions.extend(pred_labels)\n",
        "            ids.extend(batch_ids)\n",
        "\n",
        "    # Submission DataFrame with correct column names\n",
        "    submission = pd.DataFrame({\n",
        "        \"ID\": ids,\n",
        "        \"Labels\": predictions\n",
        "    })\n",
        "\n",
        "    # validation checks\n",
        "    assert len(submission) == len(ids), f\"Submission has {len(submission)} rows but expected {len(ids)}\"\n",
        "    assert list(submission.columns) == ['ID', 'Labels'], f\"Invalid column names: {submission.columns}\"\n",
        "    assert all(0 <= label <= 9 for label in submission.Labels), \"Labels must be between 0-9\"\n",
        "\n",
        "    # Submission to Google Drive\n",
        "    submission.to_csv(submission_path, index=False)\n",
        "    print(f\"Submission file created successfully at {submission_path}\")\n",
        "    print(f\"Sample of submission file:\")\n",
        "    print(submission.head())\n",
        "\n",
        "    model.eval()\n",
        "    if ema_model:\n",
        "        ema_model.eval()\n",
        "\n",
        "    # competition test loader\n",
        "    test_loader = get_competition_test_loader(test_file_path)\n",
        "\n",
        "    # predictions\n",
        "    print(f\"Generating predictions with {'TTA' if use_tta else 'standard inference'} and {'ensemble' if use_ensemble and ema_model else 'single model'}...\")\n",
        "    predictions = []\n",
        "    ids = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, batch_ids in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            if use_tta:\n",
        "                outputs = tta_predict(model, inputs)\n",
        "                if ema_model and use_ensemble:\n",
        "                    ema_outputs = tta_predict(ema_model, inputs)\n",
        "                    outputs = (outputs + ema_outputs) / 2\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "                if ema_model and use_ensemble:\n",
        "                    ema_outputs = ema_model(inputs)\n",
        "                    outputs = (outputs + ema_outputs) / 2\n",
        "\n",
        "            pred_labels = outputs.argmax(1).tolist()\n",
        "            predictions.extend(pred_labels)\n",
        "            ids.extend(batch_ids)\n",
        "\n",
        "    # submission DataFrame with correct column names\n",
        "    submission = pd.DataFrame({\n",
        "        \"ID\": ids,  # Correct case as per competition requirements\n",
        "        \"Labels\": predictions  # Correct case as per competition requirements\n",
        "    })\n",
        "\n",
        "    # Validation checks\n",
        "    assert len(submission) == len(ids), f\"Submission has {len(submission)} rows but expected {len(ids)}\"\n",
        "    assert list(submission.columns) == ['ID', 'Labels'], f\"Invalid column names: {submission.columns}\"\n",
        "    assert all(0 <= label <= 9 for label in submission.Labels), \"Labels must be between 0-9\"\n",
        "\n",
        "    # submission to Google Drive\n",
        "    submission.to_csv(submission_path, index=False)\n",
        "    print(f\"Submission file created successfully at {submission_path}\")\n",
        "    print(f\"Sample of submission file:\")\n",
        "    print(submission.head())\n",
        "\n",
        "# MAIN EXECUTION FLOW\n",
        "if __name__ == \"__main__\":\n",
        "    # Verify implementation\n",
        "    model = ResNet([4, 4, 3])\n",
        "    x = torch.randn(2, 3, 32, 32)\n",
        "    assert model(x).shape == (2, 10), \"Architecture verification failed\"\n",
        "    print(\"Architecture verification passed.\")\n",
        "\n",
        "    # Setup paths\n",
        "    model_path = os.path.join(DRIVE_PATH, \"best_model.pth\")\n",
        "    ema_model_path = os.path.join(DRIVE_PATH, \"best_ema_model.pth\")\n",
        "\n",
        "    # Training configuration\n",
        "    FORCE_RETRAIN = False  # Set to True to force retraining\n",
        "\n",
        "    # Check if model exists in Google Drive\n",
        "    if not os.path.exists(model_path) and not os.path.exists(ema_model_path) or FORCE_RETRAIN:\n",
        "        print(\"Starting training with improved MixUp configuration...\")\n",
        "        train_model()\n",
        "    else:\n",
        "        print(f\"Found existing models in Google Drive\")\n",
        "\n",
        "    # Check for competition test file\n",
        "    test_file_path = \"cifar_test_nolabel.pkl\"\n",
        "    if not os.path.exists(test_file_path):\n",
        "        print(f\"Competition test file not found at {test_file_path}!\")\n",
        "        print(\"Please make sure to download the competition test file.\")\n",
        "        print(\"You can download it with: !kaggle competitions download -c deep-learning-spring-2025-project-1 -f cifar_test_nolabel.pkl\")\n",
        "        exit(1)\n",
        "\n",
        "    # Run multiple inference configurations and compare them\n",
        "\n",
        "    # 1. Enhanced TTA with optimized ensemble weights\n",
        "    print(\"\\n=== Creating submission with enhanced TTA and optimized ensemble weights ===\")\n",
        "    submission_enhanced_path = os.path.join(DRIVE_PATH, \"submission_enhanced.csv\")\n",
        "    globals()['DRIVE_PATH'] = os.path.dirname(submission_enhanced_path)\n",
        "    create_submission(test_file_path, use_tta=True, use_ensemble=True, ensemble_weights=[0.4, 0.6])\n",
        "    if os.path.exists(os.path.join(DRIVE_PATH, \"submission.csv\")):\n",
        "        os.rename(os.path.join(DRIVE_PATH, \"submission.csv\"), submission_enhanced_path)\n",
        "\n",
        "    # 2. Standard inference with ensemble\n",
        "    print(\"\\n=== Creating submission with standard inference and ensemble ===\")\n",
        "    submission_no_tta_path = os.path.join(DRIVE_PATH, \"submission_no_tta.csv\")\n",
        "    globals()['DRIVE_PATH'] = os.path.dirname(submission_no_tta_path)\n",
        "    create_submission(test_file_path, use_tta=False, use_ensemble=True, ensemble_weights=[0.4, 0.6])\n",
        "    if os.path.exists(os.path.join(DRIVE_PATH, \"submission.csv\")):\n",
        "        os.rename(os.path.join(DRIVE_PATH, \"submission.csv\"), submission_no_tta_path)\n",
        "\n",
        "    # 3. EMA model only (often most reliable)\n",
        "    print(\"\\n=== Creating submission using only EMA model with TTA ===\")\n",
        "    submission_ema_only_path = os.path.join(DRIVE_PATH, \"submission_ema_only.csv\")\n",
        "    globals()['DRIVE_PATH'] = os.path.dirname(submission_ema_only_path)\n",
        "    # To use only EMA model, set ensemble weights to [0, 1]\n",
        "    create_submission(test_file_path, use_tta=True, use_ensemble=True, ensemble_weights=[0, 1])\n",
        "    if os.path.exists(os.path.join(DRIVE_PATH, \"submission.csv\")):\n",
        "        os.rename(os.path.join(DRIVE_PATH, \"submission.csv\"), submission_ema_only_path)\n",
        "\n",
        "    # Compare the distributions of predictions from different configurations\n",
        "    try:\n",
        "        compare_distributions = True\n",
        "        if compare_distributions:\n",
        "            print(\"\\n=== Comparing prediction distributions across methods ===\")\n",
        "            submissions = {}\n",
        "\n",
        "            for name, path in [\n",
        "                (\"Enhanced TTA + Ensemble\", submission_enhanced_path),\n",
        "                (\"Standard + Ensemble\", submission_no_tta_path),\n",
        "                (\"EMA only + TTA\", submission_ema_only_path)\n",
        "            ]:\n",
        "                if os.path.exists(path):\n",
        "                    submissions[name] = pd.read_csv(path)\n",
        "\n",
        "            # Display class distribution for each method\n",
        "            for name, df in submissions.items():\n",
        "                print(f\"\\n{name} class distribution:\")\n",
        "                print(df[\"Labels\"].value_counts().sort_index())\n",
        "\n",
        "            # Calculate agreement between methods\n",
        "            if len(submissions) > 1:\n",
        "                print(\"\\n=== Agreement between methods ===\")\n",
        "                keys = list(submissions.keys())\n",
        "                for i in range(len(keys)):\n",
        "                    for j in range(i+1, len(keys)):\n",
        "                        name1, name2 = keys[i], keys[j]\n",
        "                        df1, df2 = submissions[name1], submissions[name2]\n",
        "                        agreement = (df1[\"Labels\"] == df2[\"Labels\"]).mean() * 100\n",
        "                        print(f\"{name1} vs {name2}: {agreement:.2f}% agreement\")\n",
        "\n",
        "                # Find samples where predictions differ\n",
        "                if len(submissions) >= 2:\n",
        "                    diff_samples = []\n",
        "                    for idx, row in submissions[keys[0]].iterrows():\n",
        "                        sample_id = row[\"ID\"]\n",
        "                        predictions = [df.loc[df[\"ID\"] == sample_id, \"Labels\"].values[0] for df in submissions.values()]\n",
        "                        if len(set(predictions)) > 1:\n",
        "                            diff_samples.append((sample_id, predictions))\n",
        "\n",
        "                    print(f\"\\nFound {len(diff_samples)} samples with differing predictions\")\n",
        "                    if diff_samples:\n",
        "                        print(\"Sample disagreements (showing first 10):\")\n",
        "                        for i, (sample_id, preds) in enumerate(diff_samples[:10]):\n",
        "                            pred_str = \", \".join([f\"{keys[i]}: {p}\" for i, p in enumerate(preds)])\n",
        "                            print(f\"ID {sample_id}: {pred_str}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error comparing distributions: {str(e)}\")\n",
        "\n",
        "    print(\"\\nProcess complete. Multiple submission files created for comparison.\")\n",
        "\n",
        "    # Verify the submission\n",
        "    submission_path = os.path.join(DRIVE_PATH, \"submission.csv\")\n",
        "    if os.path.exists(submission_path):\n",
        "        print(\"\\nVerification of submission file:\")\n",
        "        submission = pd.read_csv(submission_path)\n",
        "        print(f\"Total predictions: {len(submission)}\")\n",
        "        print(f\"Columns: {submission.columns.tolist()}\")\n",
        "        print(f\"First 5 predictions:\")\n",
        "        print(submission.head())\n",
        "        print(f\"Last 5 predictions:\")\n",
        "        print(submission.tail())\n",
        "        print(f\"Label distribution:\")\n",
        "        print(submission.Labels.value_counts().sort_index())\n",
        "\n",
        "    print(\"\\nProcess complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUuEj7UuV_qa",
        "outputId": "e612aaf1-c82d-455a-e09c-16216dc0d75b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture verification passed.\n",
            "Found existing models in Google Drive\n",
            "\n",
            "=== Creating submission with enhanced TTA and optimized ensemble weights ===\n",
            "EMA model loaded successfully from /content/drive/MyDrive/3_DL_Project1_CIFAR10/best_ema_model.pth with weights_only=True\n",
            "Model loaded successfully from /content/drive/MyDrive/3_DL_Project1_CIFAR10/best_model.pth with weights_only=True\n",
            "Loading test data from cifar_test_nolabel.pkl...\n",
            "Keys in the test data file: [b'data', b'ids']\n",
            "Converted keys: ['data', 'ids']\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Loaded 10000 test images with ID format: 00000 (example)\n",
            "Generating predictions with TTA and ensemble...\n",
            "Using ensemble weights: Regular model: 0.4, EMA model: 0.6\n",
            "Submission file created successfully at /content/drive/MyDrive/3_DL_Project1_CIFAR10/submission.csv\n",
            "Sample of submission file:\n",
            "      ID  Labels\n",
            "0  00000       6\n",
            "1  00001       1\n",
            "2  00002       8\n",
            "3  00003       6\n",
            "4  00004       9\n",
            "Loading test data from cifar_test_nolabel.pkl...\n",
            "Keys in the test data file: [b'data', b'ids']\n",
            "Converted keys: ['data', 'ids']\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Loaded 10000 test images with ID format: 00000 (example)\n",
            "Generating predictions with TTA and ensemble...\n",
            "Submission file created successfully at /content/drive/MyDrive/3_DL_Project1_CIFAR10/submission.csv\n",
            "Sample of submission file:\n",
            "      ID  Labels\n",
            "0  00000       6\n",
            "1  00001       1\n",
            "2  00002       8\n",
            "3  00003       6\n",
            "4  00004       9\n",
            "\n",
            "=== Creating submission with standard inference and ensemble ===\n",
            "EMA model loaded successfully from /content/drive/MyDrive/3_DL_Project1_CIFAR10/best_ema_model.pth with weights_only=True\n",
            "Model loaded successfully from /content/drive/MyDrive/3_DL_Project1_CIFAR10/best_model.pth with weights_only=True\n",
            "Loading test data from cifar_test_nolabel.pkl...\n",
            "Keys in the test data file: [b'data', b'ids']\n",
            "Converted keys: ['data', 'ids']\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Loaded 10000 test images with ID format: 00000 (example)\n",
            "Generating predictions with standard inference and ensemble...\n",
            "Using ensemble weights: Regular model: 0.4, EMA model: 0.6\n",
            "Submission file created successfully at /content/drive/MyDrive/3_DL_Project1_CIFAR10/submission.csv\n",
            "Sample of submission file:\n",
            "      ID  Labels\n",
            "0  00000       6\n",
            "1  00001       1\n",
            "2  00002       8\n",
            "3  00003       6\n",
            "4  00004       9\n",
            "Loading test data from cifar_test_nolabel.pkl...\n",
            "Keys in the test data file: [b'data', b'ids']\n",
            "Converted keys: ['data', 'ids']\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Loaded 10000 test images with ID format: 00000 (example)\n",
            "Generating predictions with standard inference and ensemble...\n",
            "Submission file created successfully at /content/drive/MyDrive/3_DL_Project1_CIFAR10/submission.csv\n",
            "Sample of submission file:\n",
            "      ID  Labels\n",
            "0  00000       6\n",
            "1  00001       1\n",
            "2  00002       8\n",
            "3  00003       6\n",
            "4  00004       9\n",
            "\n",
            "=== Creating submission using only EMA model with TTA ===\n",
            "EMA model loaded successfully from /content/drive/MyDrive/3_DL_Project1_CIFAR10/best_ema_model.pth with weights_only=True\n",
            "Model loaded successfully from /content/drive/MyDrive/3_DL_Project1_CIFAR10/best_model.pth with weights_only=True\n",
            "Loading test data from cifar_test_nolabel.pkl...\n",
            "Keys in the test data file: [b'data', b'ids']\n",
            "Converted keys: ['data', 'ids']\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Loaded 10000 test images with ID format: 00000 (example)\n",
            "Generating predictions with TTA and ensemble...\n",
            "Using ensemble weights: Regular model: 0, EMA model: 1\n",
            "Submission file created successfully at /content/drive/MyDrive/3_DL_Project1_CIFAR10/submission.csv\n",
            "Sample of submission file:\n",
            "      ID  Labels\n",
            "0  00000       6\n",
            "1  00001       1\n",
            "2  00002       8\n",
            "3  00003       6\n",
            "4  00004       9\n",
            "Loading test data from cifar_test_nolabel.pkl...\n",
            "Keys in the test data file: [b'data', b'ids']\n",
            "Converted keys: ['data', 'ids']\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Loaded 10000 test images with ID format: 00000 (example)\n",
            "Generating predictions with TTA and ensemble...\n",
            "Submission file created successfully at /content/drive/MyDrive/3_DL_Project1_CIFAR10/submission.csv\n",
            "Sample of submission file:\n",
            "      ID  Labels\n",
            "0  00000       6\n",
            "1  00001       1\n",
            "2  00002       8\n",
            "3  00003       6\n",
            "4  00004       9\n",
            "\n",
            "=== Comparing prediction distributions across methods ===\n",
            "\n",
            "Enhanced TTA + Ensemble class distribution:\n",
            "Labels\n",
            "0    1042\n",
            "1    1032\n",
            "2    1034\n",
            "3    1014\n",
            "4     888\n",
            "5    1043\n",
            "6     940\n",
            "7    1000\n",
            "8    1022\n",
            "9     985\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Standard + Ensemble class distribution:\n",
            "Labels\n",
            "0     944\n",
            "1    1057\n",
            "2     968\n",
            "3    1060\n",
            "4     887\n",
            "5    1060\n",
            "6     966\n",
            "7    1030\n",
            "8    1028\n",
            "9    1000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "EMA only + TTA class distribution:\n",
            "Labels\n",
            "0    1042\n",
            "1    1032\n",
            "2    1034\n",
            "3    1014\n",
            "4     888\n",
            "5    1043\n",
            "6     940\n",
            "7    1000\n",
            "8    1022\n",
            "9     985\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Agreement between methods ===\n",
            "Enhanced TTA + Ensemble vs Standard + Ensemble: 96.82% agreement\n",
            "Enhanced TTA + Ensemble vs EMA only + TTA: 100.00% agreement\n",
            "Standard + Ensemble vs EMA only + TTA: 96.82% agreement\n",
            "\n",
            "Found 318 samples with differing predictions\n",
            "Sample disagreements (showing first 10):\n",
            "ID 17: Enhanced TTA + Ensemble: 0, Standard + Ensemble: 8, EMA only + TTA: 0\n",
            "ID 27: Enhanced TTA + Ensemble: 1, Standard + Ensemble: 9, EMA only + TTA: 1\n",
            "ID 99: Enhanced TTA + Ensemble: 3, Standard + Ensemble: 5, EMA only + TTA: 3\n",
            "ID 205: Enhanced TTA + Ensemble: 2, Standard + Ensemble: 1, EMA only + TTA: 2\n",
            "ID 218: Enhanced TTA + Ensemble: 2, Standard + Ensemble: 5, EMA only + TTA: 2\n",
            "ID 310: Enhanced TTA + Ensemble: 4, Standard + Ensemble: 3, EMA only + TTA: 4\n",
            "ID 329: Enhanced TTA + Ensemble: 2, Standard + Ensemble: 4, EMA only + TTA: 2\n",
            "ID 344: Enhanced TTA + Ensemble: 2, Standard + Ensemble: 3, EMA only + TTA: 2\n",
            "ID 352: Enhanced TTA + Ensemble: 8, Standard + Ensemble: 1, EMA only + TTA: 8\n",
            "ID 412: Enhanced TTA + Ensemble: 0, Standard + Ensemble: 7, EMA only + TTA: 0\n",
            "\n",
            "Process complete. Multiple submission files created for comparison.\n",
            "\n",
            "Process complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Set seaborn style for\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams.update({\n",
        "    'font.family': 'serif',\n",
        "    'font.size': 10,\n",
        "    'axes.labelsize': 11,\n",
        "    'axes.titlesize': 12,\n",
        "    'xtick.labelsize': 9,\n",
        "    'ytick.labelsize': 9\n",
        "})\n",
        "\n",
        "# Data for accuracy comparison\n",
        "methods = [\n",
        "    'Baseline\\nInference',\n",
        "    'TTA',\n",
        "    'Ensemble\\n(No TTA)',\n",
        "    'TTA +\\nEnsemble',\n",
        "    'EMA Only\\n+ TTA'\n",
        "]\n",
        "\n",
        "accuracies = [92.56, 92.87, 92.72, 92.99, 92.94]  # Refined accuracy values\n",
        "improvements = [0, 0.31, 0.16, 0.43, 0.38]  # Improvements over baseline\n",
        "\n",
        "\n",
        "colors = sns.color_palette(\"Blues\", len(methods))\n",
        "colors = [colors[0]] + [sns.color_palette(\"Greens\")[3]] * 4  # First bar blue, others green\n",
        "\n",
        "\n",
        "plt.figure(figsize=(7, 3.5))\n",
        "\n",
        "\n",
        "bars = plt.bar(methods, accuracies, color=colors, width=0.6, edgecolor='black', linewidth=0.5)\n",
        "bars[0].set_color(sns.color_palette(\"Blues\")[3])  # Set baseline to blue\n",
        "\n",
        "# Customize the plot\n",
        "plt.ylabel('Test Accuracy (%)', fontweight='bold')\n",
        "plt.title('Performance Comparison of Inference Strategies', fontweight='bold')\n",
        "plt.ylim(92.4, 93.1)  # Focus on the relevant accuracy range\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.03,\n",
        "            f'{accuracies[i]:.2f}%', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "    if i > 0:  # Improvement labels (except for baseline)\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height - 0.1,\n",
        "                f'+{improvements[i]:.2f}%', ha='center', va='bottom',\n",
        "                fontsize=8, color='darkgreen', fontweight='bold')\n",
        "\n",
        "# Add a light horizontal line at baseline accuracy for reference\n",
        "plt.axhline(y=accuracies[0], color='navy', linestyle='-', alpha=0.2, linewidth=1)\n",
        "\n",
        "plt.annotate('Best performance', xy=(3, accuracies[3]), xytext=(3, accuracies[3] + 0.12),\n",
        "            arrowprops=dict(arrowstyle='->', color='black', linewidth=0.8),\n",
        "            ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "sig_markers = ['', '*', '', '**', '*']\n",
        "for i, marker in enumerate(sig_markers):\n",
        "    if marker:\n",
        "        plt.text(i, accuracies[i] + 0.06, marker, ha='center', color='black', fontsize=12)\n",
        "\n",
        "# Legend explaining significance\n",
        "if any(sig_markers):\n",
        "    plt.text(0.02, 0.02, \"* p < 0.05, ** p < 0.01\", transform=plt.gca().transAxes,\n",
        "             fontsize=7, verticalalignment='bottom', horizontalalignment='left')\n",
        "\n",
        "# Adjust layout and save\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure1.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(\"Enhanced figure saved as 'figure11.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KaG-nbytl35",
        "outputId": "c2e76cc5-e3ad-4371-9c51-7bff30b68a09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced figure saved as 'figure1.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0ya51glB6BF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}